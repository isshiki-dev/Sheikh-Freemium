# Sheikh-Freemium: Visual CoT Training Requirements
# Based on Zebra-CoT and HuggingFace TRL best practices

# =============================================================================
# Core Deep Learning
# =============================================================================
torch>=2.1.0
torchvision>=0.16.0

# =============================================================================
# Transformers and NLP
# =============================================================================
transformers>=4.40.0
tokenizers>=0.19.0
accelerate>=0.27.0
datasets>=2.18.0

# =============================================================================
# Parameter-Efficient Fine-Tuning
# =============================================================================
peft>=0.10.0
bitsandbytes>=0.43.0  # For 4-bit quantization

# =============================================================================
# TRL (Transformer Reinforcement Learning)
# =============================================================================
trl>=0.8.0

# =============================================================================
# HuggingFace Hub
# =============================================================================
huggingface_hub>=0.22.0
hf_xet  # For large file handling

# =============================================================================
# Image Processing
# =============================================================================
Pillow>=10.0.0

# =============================================================================
# Data & Utilities
# =============================================================================
numpy>=1.24.0
pyyaml>=6.0
jsonschema>=4.0.0
tqdm>=4.65.0

# =============================================================================
# Logging & Monitoring (Optional)
# =============================================================================
tensorboard>=2.15.0
# wandb>=0.16.0  # Uncomment for Weights & Biases

# =============================================================================
# Flash Attention (Optional - Install Separately)
# =============================================================================
# pip install flash_attn --no-build-isolation

# =============================================================================
# Development
# =============================================================================
flake8>=6.0.0
black>=23.0.0
isort>=5.12.0
